[**中文说明**](README.md) | [**English**](README_En.md)

<p align="center">
    <br>
    <img src="image/tag1.png" width="400" />
    <br>
<p>
<br>

<p align="center">
        <a href="https://www.modelscope.cn/models?name=clip&tasks=multi-modal-embedding">ModelScope</a>&nbsp ｜ &nbsp<a href="https://www.modelscope.cn/studios/damo/chinese_clip_applications/summary">Demo</a>&nbsp ｜ &nbsp<a href="https://arxiv.org/abs/2211.01335">Paper</a>&nbsp ｜ &nbspBlog
</p>
<br><br>

本项目为CLIP模型的**中文**版本，使用大规模中文数据进行训练（~2亿图文对），旨在帮助用户快速实现中文领域的[图文特征&相似度计算](#API快速上手)、[跨模态检索](#跨模态检索)、[零样本图片分类](#零样本图像分类)等任务。本项目代码基于<b>[open_clip project](https://github.com/mlfoundations/open_clip)</b>建设，并针对中文领域数据以及在中文数据上实现更好的效果做了优化。本项目提供了API、训练代码和测试代码，下文中将详细介绍细节。
<br><br>
# 数据集名称

## 项目简介
这个项目提供了一个[数据集名称]，用于[数据集的用途和目标]。由于数据集过大，数据存储在[Google Drive/其他存储地址]上。

## 数据集描述
有关数据集的详细信息，请查看 [data/documentation/data_description.md](./data/documentation/data_description.md)。

## 获取数据集
数据集可以从以下链接下载：
[数据集下载链接](https://drive.google.com/your_link)

## 使用条款
请查看 [LICENSE](./LICENSE) 文件以了解使用条款。

## 贡献
欢迎贡献！请查看 [contribution_guide.md](./documentation/contribution_guide.md)。
